---
title: "Comparing C Compilers, Assembly, and Rust on ARM"
date: "2025-10-30"
---

Traditionally on this site, I have focused on projects I have done which use hardware or software to create a specific product that I can show the result of very simply, and with a output any user can understand, and with the right knowledge, use. Sometimes, however, I like to do some more analytical projects to better understand how something works and present that information as both a demonstration of research and as a way to preserve what I’ve learned. In the past, this was random things like analyzing Zipf’s law or generating a list of all digraphs by how common they are in literature. Today, I want to present a more practical experiment to better understand how different compilers compare and how efficient they are when compared to hand coded <a href="https://en.wikipedia.org/wiki/Assembly">assembly</a>.

To being, let’s go over the setup. The code is <a href="https://github.com/TrojanPinata/CRC_Benchmark">here on GitHub</a>, if you want to follow along. First thing’s first, I am using this project to get better at <a href="https://armasm.com/docs/getting-to-hello-world/basics/">ARMv8 assembly</a>, and as such I am going to run these tests on a <a href="https://en.wikipedia.org/wiki/Raspberry_Pi">Raspberry Pi 5</a> and benchmark with the <a href="https://en.wikipedia.org/wiki/Perf_(Linux)">perf</a> command. This will add some consistency and I will do five runs per compiler/set of options. For this project, I wrote a <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">Cyclical Redundancy Check (CRC)</a> program which generates a 32 bit value representing a repeatable sequence of 10 MB. For those curious, the repeatable sequence is i * 29 + 13 where i is the position of the byte and any values are truncated to eight bits. This program is then written five other times, with each version representing either a different language or language with hardware optimizations. I chose a CRC since it is a realistic application of something the processor would do, and isn’t something like a <a href="https://en.wikipedia.org/wiki/Fibonacci_sequence">fibonacci sequence</a>, which is more synthetic and not optimized on a hardware level.

The <a href="https://en.wikipedia.org/wiki/ARM_Cortex-A76">ARM A76 CPU</a> on the Pi 5 has <a href="https://en.wikipedia.org/wiki/ARM_architecture_family#Advanced_SIMD_(Neon)">hardware CRC</a> processing, which using certain commands and libraries can be used by a program to vastly speed up CRC generation. Thus, the primary things this experiment will be testing are choice of compiler, hardware optimizations, compiler optimizations based on speed, architecture specific optimizations, and effect of loop unrolling. To minor extent, we will also compare the performance of the rust compiler as well, just for fun. Assembly will be loaded and linked with GCC, though no optimizations occur when doing this and the results were comparable to doing it by had with the default assembler. As should be obvious, the primary language for this project is C, and the compilers we will be testing are <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>, <a href="https://en.wikipedia.org/wiki/Clang">Clang</a>, <a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler">TCC</a>, and <a href="https://developer.arm.com/Tools%20and%20Software/Arm%20Compiler%20for%20Embedded">ARMClang</a>.

The naming of the programs on the GitHub should be straightforward, but to clarify before starting, optimized just means it uses the crc32 hardware module in the CPU while unoptimized does not. TCC does not support this feature, and thus will not have those results. Rust will simply use the crc32c crate, which while not crc32b like everything else, is fine enough and the difference is negligible for this.

To begin the experiment, I went ahead and installed each compiler, and immediately had issues with ARMClang. ARM adds some licensing requirements for their compilers which for some reason, caused a lot of issues when installing and trying to get proper licensing. This alone is pretty egregious, but what makes it worse is that in all of the research and testing I did (on different, less conformal systems) ARMClang produced nearly identical results to stock Clang, so for the sake of the experiment I will be forgoing testing it. Once I had all of the compilers installed, I developed a simple bash script for reading commands from a text file. This file has every command needed to run every combination of compiler options and languages. I did this mostly for speed, but it also made everything more consistent between runs. I will skip the part where I talk about running the whole thing to keep this somewhat straightforward and instead, let’s just get right to the data.

<a href="https://docs.google.com/spreadsheets/d/1zFoB-Re2FUpJ8RmOci6keissW4T4M-J4HF-Kcw57qKA/edit?usp=drive_link">Results</a>

I apologize for it being a simple spreadsheet, but I tried some different presentation options and I found that they were all either miserable to look at or did not properly represent the data in a way that makes sense.

To describe what you are looking at, let me first explain how this works. The primary independent variables are the compiler and the compiler options. Each compiler option cannot be quantified, which is what makes this difficult to represent. What we can see from this data is that the age old myth that raw assembly is faster than compiled code is only sometimes true. <a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">Compiler optimizations</a> have gotten good enough that when specifically targeting a specific CPU model and architecture, code can be optimized to be as efficient as possible – moreso than a human. When just using optimization levels (O0-Ofast), we can see some improvement, but what is really pronounced is the performance advantage compiling with unrolled loops or the specific CPU has. This is even more pronounced when looking at the hardware optimizations the A76 CPU has with the CRC hardware module. That alone is capable of improving performance by 10x.

The data shows that compiler choice doesn’t matter nearly as much as the options used. It seems that each compiler is similar enough these days that the end results can be as optimized or unoptimized as you want and can have any amount of hardware optimizations and still perform similarly. The exception to this rule is TCC, which is not good and I don’t fully understand why anyone would use it on a PC or modern SBC when Clang and GCC exist and even the most basic computers can run them. (Actually, I can see a situation where someone needs to compile on a <a href="https://en.wikipedia.org/wiki/BBC_Micro">BBC Micro</a> or microcontroller or something super underpowered, so that is it’s purpose, though it probably should do a better job with hardware optimization support on those systems since they need as much power as they can get). Rust performed extremely well in this situation, even coming close to the best results of C. But the real question of all of this is how assembly compares.

I am not a professional when it comes to assembly. I am decent at MIPS, I have some experience with x86, and this is my first time writing any decent ARM. That being said, I think this program is a accurate representation of the C code, and should be optimized similarly. I tried to do this line by line to make it as similar as possible, and even included some of the C commands to make it even more similar (as in comparable with printf). The result? It’s closer than you think. Raw assembly was only 34% faster than unoptimized C. Once there was even a little bit of compiler optimization it wasn’t even close, C was just that much faster when the compiler can optimize for branching and predictions. Assembly with hardware optimizations could hang out a bit better, and was 94% faster than base C, and 60% faster than base assembly – a runtime that was within tolerance of the fastest times listed.

I should note that there is a +/- 0.002 second tolerance on all of these values that was consistent regardless of the number of runs. With that said, I would say that adding hardware optimizations and a specific CPU when possible, as well as the any level of optimization other than zero is good enough for most use cases with GCC and Clang. For ease of use, I would even go as far as to say the user experience is probably a bit better in C for both writing and running.

This was a fun experiment, and at the end of the day I got to test a long standing statement about compiler use and gather real data about how they actually preform when compared to essentially machine code. This data has shown me that knowing the specific platform and hardware can allow code to be extremely optimized for a specific use case, taught me that assembly is faster when optimizations are not available, and even gave me some data to use when deciding which compiler I should be using for compiling C on my own computer. And as a bonus, I got to learn more ARM assembly. 

That’s all for this one. Hopefully you learned something or at least had fun reading.



Until next time.
